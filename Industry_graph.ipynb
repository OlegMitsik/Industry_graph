{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import minmax_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and consolidating input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_edges_orig = pd.read_csv('df_edges_orig.csv')\n",
    "df_nodes_train = pd.read_csv('df_nodes_train.csv')\n",
    "df_nodes_test_publ = pd.read_csv('df_nodes_test_publ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merged = pd.merge(df_edges_orig, df_nodes_train.rename(columns={'Feat3': 'Feat3Left', \n",
    "                'Feat4': 'Feat4Left', 'Y': 'YLeft'}), how = \"left\", left_on = 'NodeLeft', right_on = 'Node')\n",
    "del train_merged['Node']\n",
    "\n",
    "train_merged = pd.merge(train_merged, df_nodes_train.rename(columns={'Feat3': 'Feat3Right', \n",
    "                'Feat4': 'Feat4Right', 'Y': 'YRight'}), how = \"left\", left_on = 'NodeRight', right_on = 'Node')\n",
    "del train_merged['Node']\n",
    "\n",
    "train_merged['SameIndustry'] = (train_merged['YLeft'] == train_merged['YRight']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference of classes on outbound payment transactions with a balanced decision tree classifier\n",
    "#### Hyper-parameters are found through a grid search of best accuracy score with 5-fold stratified cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid accuracy scores on development set:\n",
      "0.879 (+/-0.001) for {'min_samples_split': 2, 'min_samples_leaf': 1}\n",
      "0.875 (+/-0.002) for {'min_samples_split': 3, 'min_samples_leaf': 1}\n",
      "0.828 (+/-0.002) for {'min_samples_split': 10, 'min_samples_leaf': 1}\n",
      "0.853 (+/-0.002) for {'min_samples_split': 2, 'min_samples_leaf': 2}\n",
      "0.853 (+/-0.001) for {'min_samples_split': 3, 'min_samples_leaf': 2}\n",
      "0.821 (+/-0.002) for {'min_samples_split': 10, 'min_samples_leaf': 2}\n",
      "0.751 (+/-0.004) for {'min_samples_split': 2, 'min_samples_leaf': 10}\n",
      "0.751 (+/-0.003) for {'min_samples_split': 3, 'min_samples_leaf': 10}\n",
      "0.751 (+/-0.003) for {'min_samples_split': 10, 'min_samples_leaf': 10}\n",
      "\n",
      "Best accuracy score is 0.879. Best parameters set found on development set:\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "X = train_merged.dropna()[['Feat1', 'Feat2', 'Feat3Right', 'Feat4Right', 'YRight']]\n",
    "y = train_merged.dropna()['SameIndustry']\n",
    "\n",
    "estm = DecisionTreeClassifier(class_weight = \"balanced\")\n",
    "tuned_parameters = [{'min_samples_split': [2, 3, 10], 'min_samples_leaf': [1, 2, 10]}]\n",
    "\n",
    "clf = GridSearchCV(estimator=estm, param_grid=tuned_parameters,\n",
    "                   cv=StratifiedKFold(n_splits=5, shuffle = True), scoring=make_scorer(accuracy_score))\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(\"Grid accuracy scores on development set:\")\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, 2 * std, params))\n",
    "print()\n",
    "print(\"Best accuracy score is %0.3f.\" % clf.best_score_, \"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)\n",
    "\n",
    "estm.set_params(**clf.best_params_)\n",
    "estm.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_merged_LeftPredict = train_merged[train_merged['YLeft'].isnull() & train_merged['YRight'].notnull()].copy()\n",
    "train_merged_LeftPredict['SameIndustry'] = estm.predict(\n",
    "                        train_merged_LeftPredict[['Feat1', 'Feat2', 'Feat3Right', 'Feat4Right', 'YRight']])\n",
    "train_merged_LeftPredict['YLeft'] = np.where(\n",
    "                    train_merged_LeftPredict['SameIndustry'], train_merged_LeftPredict['YRight'], np.nan)\n",
    "train_merged.update(train_merged_LeftPredict)\n",
    "del train_merged_LeftPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference of classes on inbound payment transactions with a balanced decision tree classifier\n",
    "#### Hyper-parameters are found through a grid search of best accuracy score with 5-fold stratified cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid accuracy scores on development set:\n",
      "0.844 (+/-0.002) for {'min_samples_split': 2, 'min_samples_leaf': 1}\n",
      "0.840 (+/-0.002) for {'min_samples_split': 3, 'min_samples_leaf': 1}\n",
      "0.805 (+/-0.001) for {'min_samples_split': 10, 'min_samples_leaf': 1}\n",
      "0.822 (+/-0.001) for {'min_samples_split': 2, 'min_samples_leaf': 2}\n",
      "0.822 (+/-0.001) for {'min_samples_split': 3, 'min_samples_leaf': 2}\n",
      "0.797 (+/-0.002) for {'min_samples_split': 10, 'min_samples_leaf': 2}\n",
      "0.744 (+/-0.003) for {'min_samples_split': 2, 'min_samples_leaf': 10}\n",
      "0.744 (+/-0.003) for {'min_samples_split': 3, 'min_samples_leaf': 10}\n",
      "0.744 (+/-0.003) for {'min_samples_split': 10, 'min_samples_leaf': 10}\n",
      "\n",
      "Best accuracy score is 0.844. Best parameters set found on development set:\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "X = train_merged.dropna()[['Feat1', 'Feat2', 'Feat3Left', 'Feat4Left', 'YLeft']]\n",
    "y = train_merged.dropna()['SameIndustry']\n",
    "\n",
    "estm = DecisionTreeClassifier(class_weight = \"balanced\")\n",
    "tuned_parameters = [{'min_samples_split': [2, 3, 10], 'min_samples_leaf': [1, 2, 10]}]\n",
    "\n",
    "clf = GridSearchCV(estimator=estm, param_grid=tuned_parameters,\n",
    "                   cv=StratifiedKFold(n_splits=5, shuffle = True), scoring=make_scorer(accuracy_score))\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(\"Grid accuracy scores on development set:\")\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, 2 * std, params))\n",
    "print()\n",
    "print(\"Best accuracy score is %0.3f.\" % clf.best_score_, \"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)\n",
    "\n",
    "estm.set_params(**clf.best_params_)\n",
    "estm.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merged_RightPredict = train_merged[train_merged['YRight'].isnull() & train_merged['YLeft'].notnull()].copy()\n",
    "train_merged_RightPredict['SameIndustry'] = estm.predict(\n",
    "                        train_merged_RightPredict[['Feat1', 'Feat2', 'Feat3Left', 'Feat4Left', 'YLeft']])\n",
    "train_merged_RightPredict['YRight'] = np.where(\n",
    "                    train_merged_RightPredict['SameIndustry'], train_merged_RightPredict['YLeft'], np.nan)\n",
    "train_merged.update(train_merged_RightPredict)\n",
    "del train_merged_RightPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction of payment amounts and values to a single variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained portion of variance: 0.97\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=1, svd_solver='full')\n",
    "pca.fit(train_merged[['Feat1', 'Feat2']])\n",
    "print('Explained portion of variance:', np.round(np.cumsum(pca.explained_variance_ratio_), 2)[0])\n",
    "train_merged['Length'] = minmax_scale(pca.transform(train_merged[['Feat1', 'Feat2']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing payments graph with semi-classified nodes and a single measure of edge length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_graph = nx.from_pandas_dataframe(df=train_merged, source='NodeLeft', target='NodeRight', \n",
    "                                       edge_attr='Length', create_using=nx.Graph())\n",
    "\n",
    "nx.set_node_attributes(G = train_graph, name = 'Y', values = [])\n",
    "for row in train_merged.iterrows():\n",
    "    if ((not np.isnan(row[1]['YLeft'])) and (row[1]['YLeft'] not in train_graph.node[row[1]['NodeLeft']]['Y'])):\n",
    "        train_graph.node[row[1]['NodeLeft']]['Y'] = train_graph.node[row[1]['NodeLeft']]['Y'] + [int(row[1]['YLeft'])]\n",
    "    if ((not np.isnan(row[1]['YRight'])) and (row[1]['YRight'] not in train_graph.node[row[1]['NodeRight']]['Y'])):\n",
    "        train_graph.node[row[1]['NodeRight']]['Y'] = train_graph.node[row[1]['NodeRight']]['Y'] + [int(row[1]['YRight'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference of classes through label propagation on payments graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_nodes_train['Feat4']\n",
    "y = df_nodes_train['Y']\n",
    "\n",
    "IndCLF = DecisionTreeClassifier(class_weight = \"balanced\", min_samples_split = 2, min_samples_leaf = 1)\n",
    "IndCLF.fit(X.values.reshape(-1, 1), y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_arr = []\n",
    "\n",
    "for trow in df_nodes_test_publ.iterrows():\n",
    "    current_node = trow[1]['Node']\n",
    "    out_val = -1\n",
    "    \n",
    "    if (train_graph.has_node(current_node)):    \n",
    "        \n",
    "        if (len(train_graph.node[current_node]['Y']) == 1):\n",
    "            out_val = train_graph.node[current_node]['Y'][0]\n",
    "        \n",
    "        else:\n",
    "            Ys = {}\n",
    "            \n",
    "            # iteration through 1st level neighbors\n",
    "            for i in iter(train_graph[current_node]):\n",
    "                if (train_graph.node[i]['Y']):\n",
    "                    for y in train_graph.node[i]['Y']:\n",
    "                        if (y in Ys.keys()):\n",
    "                            Ys[y] += train_graph[current_node][i]['Length']\n",
    "                        else:\n",
    "                            Ys[y] = train_graph[current_node][i]['Length']    \n",
    "                            \n",
    "                # iteration through 2nd level neighbors\n",
    "                for j in iter(train_graph[i]):\n",
    "                    if (j != current_node):\n",
    "                        if (train_graph.node[j]['Y']):\n",
    "                            for y in train_graph.node[j]['Y']:\n",
    "                                if (y in Ys.keys()):\n",
    "                                    Ys[y] += train_graph[current_node][i]['Length'] * train_graph[i][j]['Length']\n",
    "                                else:\n",
    "                                    Ys[y] = train_graph[current_node][i]['Length'] * train_graph[i][j]['Length']\n",
    "        \n",
    "            if (Ys.keys()):\n",
    "                # selecting most frequent class among nearest neighbors\n",
    "                out_val = max(Ys, key=Ys.get)\n",
    "                \n",
    "            else:\n",
    "                # using dummy classifier if graph data does not help to make inference\n",
    "                out_val = IndCLF.predict(trow[1]['Feat4'].reshape(1, -1))[0]\n",
    "        \n",
    "    else:\n",
    "        # using dummy classifier if graph data does not help to make inference\n",
    "        out_val = IndCLF.predict(trow[1]['Feat4'].reshape(1, -1))[0]\n",
    "        \n",
    "    out_arr.append([current_node, out_val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Out_pd = pd.DataFrame(out_arr)\n",
    "Out_pd.columns = ['Node', 'Y']\n",
    "Out_pd.to_csv('OlegMitsik-13112017-SberbankIndustry.csv', header = True, index = False, mode = 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
